# Machine Learning Model Serving API

## Problem
Serve ML models via API with versioning and A/B testing.

## What You'll Learn
- Model versioning & deployment
- Inference optimization
- Model monitoring & drift detection
- Batch vs real-time inference
- Feature store integration

## Tech Stack
- Node.js
- TensorFlow.js/ONNX
- S3
- Lambda

## War Story
"Built ML serving infrastructure handling 10K predictions/sec with <50ms latency"

## Interview Topics
- ML operations
- Model serving
- Inference optimization

## Duration
2 weeks
